{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5493f72-9e66-405e-8427-6f012049896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist dataset\n",
    "# has handwritten digits form 0 to 9 about 70 thousand images are provided alogn with the labels, \n",
    "# 60 thousand for training and 10 thousand for testin all the images have same size of 28 X 28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efdf278-75ff-4fc7-a8eb-ba4ba9cbd385",
   "metadata": {},
   "source": [
    "# Importing necessar libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc365cae-663f-4c76-b27f-302140eded56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported succesfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "print('Libraries imported succesfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3209b-6644-421d-ab49-0653058ff7a6",
   "metadata": {},
   "source": [
    "# load the mnist data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a20877-c7f3-4191-a8e4-1003e5b7f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d8af6b-dbf0-4cfa-be13-56f302bfec37",
   "metadata": {},
   "source": [
    "# preprocess the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff06fa70-6125-40d7-98ae-24c1a5cd82d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# as ANN can accept only 10 data, reshape images  from 2d to 1d\n",
    "Xm_train = x_train.reshape((60000, 784))\n",
    "Xm_test = x_test.reshape((10000,784))\n",
    "print(Xm_train.shape, Xm_test.shape)\n",
    "\n",
    "#normalizing all the images to 0 to 1.\n",
    "Xm_train=Xm_train/255\n",
    "Xm_test=Xm_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc15ece-6c8a-4ef1-a7db-3dbba62bcaac",
   "metadata": {},
   "source": [
    "# Encode the label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f432dcc2-d4f1-467e-abf4-0e27de204d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Ymtrain = to_categorical(y_train)\n",
    "ymtest = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6066eb-789e-4e45-9791-400e6c5e8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:3])\n",
    "print(Ymtrain[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8dcd5-26c3-4663-b253-46c76ff45b2c",
   "metadata": {},
   "source": [
    "# now build neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25dab949-5fd0-4fa0-831a-2b3e937640b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m200,960\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,530</span> (795.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,530\u001b[0m (795.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,530</span> (795.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m203,530\u001b[0m (795.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ANN_model = Sequential()\n",
    "ANN_model.add(Dense(input_shape=[784],units=256,activation='relu'))\n",
    "ANN_model.add(Dense(units=10, activation='sigmoid'))\n",
    "\n",
    "ANN_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c658f-6f3a-4216-9b73-fea7f6d01d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.8899 - loss: 0.3774\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.0969\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0622\n",
      "Epoch 4/5\n",
      "\u001b[1m1527/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0372"
     ]
    }
   ],
   "source": [
    "ANN_model.fit(Xm_train,Ymtrain, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb74c8-ed2e-4db8-a667-a51fdca15593",
   "metadata": {},
   "source": [
    "# Single imapre prediction. also called as sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bae511-9e2f-4129-af7e-7341c4656741",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[4000],cmap = 'Greens')\n",
    "plt.show()\n",
    "R = ANN_model.predict(Xm_test[4000:4001])\n",
    "print(f\"Probabiliteis {R}\")\n",
    "print(f\"The digit is: {np.argmax(R)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4c78e-6d0c-41c6-9cf5-f75ccf294065",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef9b53f-d6f5-49e8-a477-56cec01800e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.save(\"handwritten_digit_ann_model_best1.h5\") #saving with hdf5 format\n",
    "ANN_model.save(\"hadnwritten_digit_ann_model_best1.keras\") # keras "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
